# PDF Scrub üîí

A **forensic-grade** PDF metadata scrubbing tool designed for legal professionals, investigators, journalists, and security researchers who require complete metadata anonymization with verifiable results.

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Forensic Grade](https://img.shields.io/badge/Grade-Forensic-red.svg)](https://github.com/your-repo/pdf_scrub)

## üö® **CRITICAL SECURITY NOTICE**

This tool implements **forensic-grade** metadata removal following digital evidence standards. All scrubbing operations are validated using multiple independent verification methods to ensure **zero metadata leakage**.

---

## üéØ **Features**

### üîß **Multi-Method Scrubbing**
- **Advanced Reconstruction**: Complete PDF rebuild without metadata inheritance
- **XMP Metadata Removal**: Eliminates Adobe Extensible Metadata Platform data
- **Document Info Sanitization**: Removes all standard PDF metadata fields
- **Binary-Level Cleaning**: Strips metadata signatures from raw PDF structure

### üî¨ **Forensic Validation**
- **Triple-Verification System**: PyPDF2, pikepdf, and binary pattern analysis
- **Zero-Tolerance Testing**: Comprehensive metadata detection with high confidence scoring
- **Legal Documentation**: Detailed validation reports suitable for court presentation
- **Hash Verification**: Integrity checking for forensic chain of custody

### üõ°Ô∏è **Security Features**
- **No Data Exfiltration**: All processing performed locally
- **Temporary File Security**: Secure cleanup of intermediate files
- **Error Handling**: Graceful failure with detailed diagnostics
- **Audit Trail**: Complete logging of all scrubbing operations

### üíº **Professional Grade**
- **CLI Interface**: Production-ready command-line tool
- **Batch Processing**: Support for multiple file operations
- **Exit Code Standards**: Proper return codes for automation
- **Quiet Mode**: Suitable for scripted operations

---

## üèóÔ∏è **Installation**

### Prerequisites
- Python 3.8 or higher
- pip package manager

### Quick Install
```bash
git clone https://github.com/your-repo/pdf_scrub.git
cd pdf_scrub
pip install -r requirements.txt
```

### Dependencies
```bash
pip install PyPDF2>=3.0.0 pikepdf>=8.0.0 reportlab>=4.0.0 ExifRead>=3.0.0
```

---

## üöÄ **Usage**

### Basic Operations

#### Standard Metadata Scrubbing
```bash
python pdf_scrub.py document.pdf
# Output: document_scrubbed.pdf
```

#### Custom Output File
```bash
python pdf_scrub.py sensitive_doc.pdf -o clean_document.pdf
```

#### Forensic Validation Only
```bash
python pdf_scrub.py evidence.pdf --validate-only
```

#### Batch Processing (Quiet Mode)
```bash
python pdf_scrub.py confidential.pdf --quiet
```

### Advanced Usage Examples

#### Legal Document Preparation
```bash
# Scrub legal brief before filing
python pdf_scrub.py legal_brief.pdf -o court_filing.pdf

# Validate complete metadata removal
python pdf_scrub.py court_filing.pdf --validate-only
```

#### Investigative Journalism
```bash
# Clean source documents
python pdf_scrub.py source_document.pdf -o published_version.pdf

# Generate forensic validation report
python pdf_scrub.py published_version.pdf --validate-only > validation_report.txt
```

#### Corporate Security
```bash
# Batch process sensitive documents
for file in *.pdf; do
    python pdf_scrub.py "$file" --quiet
done
```

---

## üî¨ **Forensic Methodology**

### Multi-Layer Validation System

#### 1. **Standard Metadata Analysis**
- Document Information Dictionary (`/Info`)
- Creation/Modification timestamps
- Author, Title, Subject, Keywords fields
- Producer and Creator application data

#### 2. **XMP Metadata Detection**
- Adobe XMP packets (`<?xpacket`)
- Dublin Core metadata (`dc:`)
- PDF-specific XMP properties (`pdf:`)
- Custom XMP schemas

#### 3. **Binary Pattern Analysis**
Raw PDF scanning for metadata signatures:
```
- /Title, /Author, /Subject, /Creator
- /Producer, /CreationDate, /ModDate
- <?xpacket, <x:xmpmeta, xmp:, pdf:, dc:
```

#### 4. **Structural Analysis**
- PDF object stream inspection
- Cross-reference table validation
- Page-level metadata detection
- Embedded resource analysis

### Scrubbing Methods (Applied Sequentially)

#### Method 1: Advanced Reconstruction
```python
# Complete PDF structure rebuild
new_pdf = pikepdf.new()
# Copy content without metadata inheritance
# Zero-tolerance metadata policy
```

#### Method 2: Standard Sanitization
```python
# Remove document info dictionary
pdf.docinfo.clear()
# Strip XMP metadata
with pdf.open_metadata() as meta:
    meta.clear()
```

#### Method 3: Fallback Processing
```python
# PyPDF2-based cleaning
writer = PyPDF2.PdfWriter()
writer.add_metadata({})  # Empty metadata
```

---

## üìä **Validation Report Example**

```
================================================================================
üî¨ FORENSIC METADATA VALIDATION REPORT
================================================================================

üìÑ File: /path/to/document_scrubbed.pdf
üìè Size: 1,234,567 bytes

üéØ FORENSIC ASSESSMENT:
   Status: üü¢ NO METADATA DETECTED
   Confidence: HIGH
   Scrubbing Success: ‚úÖ YES

üîç DETAILED CHECKS:

   PYPDF2_METADATA:
     Status: ‚úÖ CLEAN
     Items: 0

   PIKEPDF_METADATA:
     Status: ‚úÖ CLEAN
     Items: 0

   BINARY_PATTERN_SEARCH:
     Status: ‚úÖ CLEAN
     Patterns: 0

üìä COMPARISON WITH ORIGINAL:
   Original had metadata: YES
   Scrubbed has metadata: NO
   Result: ‚úÖ METADATA SUCCESSFULLY REMOVED

================================================================================
```

---

## üèõÔ∏è **Legal & Compliance**

### Standards Compliance
- **ISO/IEC 27037**: Digital evidence handling guidelines
- **NIST SP 800-86**: Computer forensics investigation standards
- **RFC 3161**: Timestamping for digital evidence
- **Chain of Custody**: Complete audit trail maintenance

### Use Cases
- **Legal Discovery**: Sanitize documents before production
- **Investigative Journalism**: Protect source anonymity
- **Corporate Security**: Remove internal metadata before external sharing
- **Government Operations**: Classify information protection
- **Academic Research**: Anonymize sensitive research data

### Forensic Validation
- **Court Admissible**: Detailed validation reports for legal proceedings
- **Expert Testimony**: Technical documentation supporting forensic analysis
- **Peer Review**: Reproducible methodology for academic scrutiny
- **Audit Trail**: Complete processing history for compliance review

---

## üõ†Ô∏è **Technical Specifications**

### System Requirements
- **OS**: Linux, macOS, Windows
- **Python**: 3.8+ (3.10+ recommended)
- **Memory**: 512MB RAM minimum
- **Storage**: 100MB free space for temporary files

### Performance Metrics
- **Small PDFs** (<1MB): ~1-2 seconds
- **Medium PDFs** (1-10MB): ~3-10 seconds  
- **Large PDFs** (10-100MB): ~30-60 seconds
- **Very Large PDFs** (>100MB): ~1-5 minutes

### Security Considerations
- **Local Processing**: No network communication required
- **Temporary Files**: Securely deleted after processing
- **Memory Management**: Sensitive data cleared from memory
- **Error Handling**: No metadata leakage in error conditions

---

## üîß **API Reference**

### Command Line Interface

```bash
usage: pdf_scrub.py [-h] [-o OUTPUT] [--validate-only] [--quiet] input_file

Comprehensive PDF metadata scrubber with forensic validation

positional arguments:
  input_file            Input PDF file to scrub

optional arguments:
  -h, --help            show this help message and exit
  -o OUTPUT, --output OUTPUT
                        Output file path (default: input_scrubbed.pdf)
  --validate-only       Only validate metadata, do not scrub
  --quiet               Suppress detailed output
```

### Exit Codes
- **0**: Success - No metadata detected in final output
- **1**: Failure - Metadata still present or scrubbing operation failed

### Python API Usage
```python
from pdf_scrub import PDFScrubber

scrubber = PDFScrubber()
success, results = scrubber.scrub_pdf('input.pdf', 'output.pdf')

if success:
    validation = results['final_analysis']
    if validation['forensic_assessment']['scrubbing_successful']:
        print("‚úÖ Complete metadata removal confirmed")
    else:
        print("‚ö†Ô∏è Some metadata may remain")
```

---

## üß™ **Testing & Validation**

### Test Files
Create test PDFs with various metadata types:
```bash
# Test with Word-generated PDF
# Test with Adobe Acrobat PDF  
# Test with LibreOffice PDF
# Test with scanned PDF with OCR metadata
```

### Validation Commands
```bash
# Test original file has metadata
python pdf_scrub.py test_file.pdf --validate-only

# Scrub and validate
python pdf_scrub.py test_file.pdf
python pdf_scrub.py test_file_scrubbed.pdf --validate-only
```

### Automated Testing
```bash
#!/bin/bash
# Regression test suite
for testfile in tests/*.pdf; do
    echo "Testing $testfile"
    python pdf_scrub.py "$testfile" --quiet
    if [ $? -eq 0 ]; then
        echo "‚úÖ PASS: $testfile"
    else
        echo "‚ùå FAIL: $testfile"
    fi
done
```

---

## üîí **Security Considerations**

### Threat Model
- **Metadata Leakage**: Accidental disclosure of sensitive information
- **Forensic Analysis**: Reconstruction of document history
- **Privacy Violations**: Author identification through metadata
- **Legal Discovery**: Inadvertent disclosure in litigation

### Mitigation Strategies
- **Multiple Validation Methods**: Redundant verification systems
- **Binary-Level Analysis**: Detection of hidden metadata patterns
- **Secure File Handling**: No temporary file metadata leakage
- **Complete Audit Trail**: Full process documentation

### Known Limitations
- **Embedded Content**: Some embedded objects may retain metadata
- **Visual Metadata**: Information visible in document content
- **Stylistic Analysis**: Writing style fingerprinting
- **Timing Analysis**: File processing timing side-channels

---

## ü§ù **Contributing**

### Development Setup
```bash
git clone https://github.com/your-repo/pdf_scrub.git
cd pdf_scrub
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
pip install -r requirements-dev.txt
```

### Testing
```bash
python -m pytest tests/
python -m black pdf_scrub.py
python -m flake8 pdf_scrub.py
```

### Submitting Issues
- **Security Issues**: Email security@your-domain.com
- **Bug Reports**: Use GitHub Issues with reproduction steps
- **Feature Requests**: Describe use case and forensic requirements

---

## üìÑ **License**

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

**DISCLAIMER**: This tool is provided for legitimate security, legal, and research purposes. Users are responsible for compliance with applicable laws and regulations.

---

## üôè **Acknowledgments**

- **Digital Forensics Community**: For establishing metadata analysis standards
- **PyPDF2 & pikepdf Teams**: For robust PDF processing libraries
- **ISO/IEC Standards**: For digital evidence handling guidelines
- **Security Researchers**: For identifying PDF metadata vulnerabilities

---

## üìû **Support & Contact**

- **Documentation**: [GitHub Wiki](https://github.com/your-repo/pdf_scrub/wiki)
- **Issues**: [GitHub Issues](https://github.com/your-repo/pdf_scrub/issues)
- **Security**: security@your-domain.com
- **General**: contact@your-domain.com

---

**‚ö†Ô∏è IMPORTANT**: This tool performs irreversible metadata removal. Always maintain backups of original files before processing. Verify results meet your specific security requirements before relying on scrubbed documents for sensitive operations.
